{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "3.8.13 (default, Mar 28 2022, 11:38:47) \n",
      "[GCC 7.5.0]\n",
      "1.12.1\n",
      "0.13.1\n"
     ]
    }
   ],
   "source": [
    "# changed\n",
    "\n",
    "import numpy as np\n",
    "#import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import sys\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.io import read_image\n",
    "\n",
    "\n",
    "# models\n",
    "from torchvision.models import convnext_tiny, ConvNeXt_Tiny_Weights\n",
    "from torchvision.models import efficientnet_v2_s, EfficientNet_V2_S_Weights\n",
    "from torchvision.models import regnet_x_8gf, RegNet_X_8GF_Weights\n",
    "from torchvision.models import swin_t, Swin_T_Weights\n",
    "from torchvision.models import wide_resnet50_2, Wide_ResNet50_2_Weights\n",
    "\n",
    "import wandb\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)\n",
    "print(sys.version)\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changed\n",
    "\n",
    "#wandb.login()\n",
    "#wandb.init(project=\"test_project_0\", entity=\"nornir\")\n",
    "\n",
    "#should be terminal inputs:\n",
    "\n",
    "# choose one model\n",
    "#model_name = 'convnext_tiny' # last block is called \"classifier\" \n",
    "# model_name = 'efficientnet_v2_s' # last block is called \"classifier\" \n",
    "model_name = 'regnet_x_8gf' # last block is called \"fc\" \n",
    "# model_name = 'swin_t'  # last block is called \"head\" \n",
    "# model_name = 'wide_resnet50_2'  # last block is called \"fc\" \n",
    "\n",
    "attribute = 'all_mass_protest' # or maybe this is a loop. Or both are loop?\n",
    "\n",
    "# ---------------------------------------\n",
    "\n",
    "hyperparameters = {\n",
    "\"model_name\" : model_name,\n",
    "\"attribute\" : attribute,\n",
    "\"learning_rate\": 0.0001,\n",
    "\"weight_decay\" : 0.05,\n",
    "'betas' : (0.9, 0.999),\n",
    "\"classes\" : 1,\n",
    "\"epochs\": 2,\n",
    "\"batch_size\": 8 # efficientnet_v2_s can max do 32 before running our of mem.\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, attribute_dict, attribute, img_dir, train = True, transform=None, target_transform=None):\n",
    "\n",
    "        # need to handle nan : do it in the df to dict..\n",
    "\n",
    "        n_img = n_img = len(attribute_dict[f'{attribute}_ens_mean'])\n",
    "        n_train = int(n_img * 0.95)\n",
    "\n",
    "        if train == True:\n",
    "\n",
    "            self.img_labels = np.array(list(zip(attribute_dict['img'], attribute_dict[f'{attribute}_ens_mean'])))[:n_train] # which is not a label but a score.. # you do not handles nans right now... \n",
    "            self.img_std = np.array(list(zip(attribute_dict['img'], attribute_dict[f'{attribute}_ens_std'])))[:n_train] # you do not handles nans right now...\n",
    "        \n",
    "        elif train == False:\n",
    "            self.img_labels = np.array(list(zip(attribute_dict['img'], attribute_dict[f'{attribute}_ens_mean'])))[n_train:] # which is not a label but a score.. # you do not handles nans right now... \n",
    "            self.img_std = np.array(list(zip(attribute_dict['img'], attribute_dict[f'{attribute}_ens_std'])))[n_train:]\n",
    "\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels[idx, 0])\n",
    "        image = read_image(img_path)\n",
    "        label = np.float32(self.img_labels[idx, 1]) #it is turned to a str above so we turn it back here\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models():\n",
    "\n",
    "    weight_dict = {'convnext_tiny': ConvNeXt_Tiny_Weights.DEFAULT,\n",
    "                'efficientnet_v2_s' : EfficientNet_V2_S_Weights.DEFAULT,\n",
    "                'regnet_x_8gf' : RegNet_X_8GF_Weights.DEFAULT,\n",
    "                'swin_t' : Swin_T_Weights.DEFAULT,\n",
    "                'wide_resnet50_2' : Wide_ResNet50_2_Weights.DEFAULT}\n",
    "\n",
    "    model_dict = {'convnext_tiny': convnext_tiny(weights = weight_dict['convnext_tiny']).to(device),\n",
    "                'efficientnet_v2_s' : efficientnet_v2_s(weights = weight_dict['efficientnet_v2_s']).to(device),\n",
    "                'regnet_x_8gf' : regnet_x_8gf(weights = weight_dict['regnet_x_8gf']).to(device),\n",
    "                'swin_t' : swin_t(weights = weight_dict['swin_t']).to(device),\n",
    "                'wide_resnet50_2' : wide_resnet50_2(weights = weight_dict['wide_resnet50_2']).to(device)}\n",
    "\n",
    "    return(weight_dict, model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change last layer\n",
    "def change_head(model_name, model, num_classes):\n",
    "\n",
    "    if model_name == 'convnext_tiny':\n",
    "        model.classifier[2] = nn.Linear(model.classifier[2].in_features, num_classes).to(device)\n",
    "        print(f'new head: {model.classifier[2]}')\n",
    "\n",
    "    elif model_name == 'efficientnet_v2_s':\n",
    "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes).to(device)\n",
    "        print(f'new head: {model.classifier[1]}')\n",
    "\n",
    "    elif model_name == 'regnet_x_8gf':\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes).to(device)\n",
    "        print(f'new head: {model.fc}')\n",
    "\n",
    "    elif model_name == 'swin_t':\n",
    "        model.head = nn.Linear(model.head.in_features, num_classes).to(device)\n",
    "        print(f'new head: {model.head}')\n",
    "\n",
    "    elif model_name == 'wide_resnet50_2':\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes).to(device)\n",
    "        print(f'new head: {model.fc}')\n",
    "\n",
    "    else:\n",
    "        print('Unddefined model name...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loader\n",
    "def make_loader(batch_size, weights, attribute):\n",
    "\n",
    "    # this is the thiong that has to change for RA...\n",
    "    # need to get attribute\n",
    "\n",
    "    #Should be in config\n",
    "    data_transforms = {\n",
    "    'train': transforms.Compose([weights.transforms(), transforms.RandomHorizontalFlip(p=0.5), transforms.RandomRotation(degrees=(0, 45)), transforms.ColorJitter(brightness=.5, hue=.2)]), \n",
    "    'test': transforms.Compose([weights.transforms()])\n",
    "    }\n",
    "\n",
    "    # Going into make loader -------------------------------\n",
    "\n",
    "    dict_dir = '/home/simon/Documents/Bodies/data/RA/dfs/' #local\n",
    "    img_dir = '/media/simon/Seagate Expansion Drive/images_spanner' #local\n",
    "\n",
    "    #dict_dir = '/home/projects/ku_00017/data/raw/bodies/RA_annotations/' # computerome\n",
    "    #img_dir = '/home/projects/ku_00017/data/raw/bodies/images_spanner' # computerome\n",
    "\n",
    "    with open(f'{dict_dir}ra_ens_annotated_dict.pkl', 'rb') as file:\n",
    "        attribute_dict = pickle.load(file)\n",
    "\n",
    "    dataloaders = {}\n",
    "    image_datasets = {}\n",
    "    \n",
    "    image_datasets['train'] = CustomImageDataset(attribute_dict, attribute, img_dir, train=True , transform=data_transforms['train'])\n",
    "    dataloaders['train'] = DataLoader(image_datasets['train'], batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    image_datasets['test'] = CustomImageDataset(attribute_dict, attribute, img_dir, train=False , transform=data_transforms['test'])\n",
    "    dataloaders['test'] = DataLoader(image_datasets['test'], batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    #image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "    #dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "\n",
    "    dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}\n",
    "    #class_names = image_datasets['train'].classes\n",
    "\n",
    "    return dataloaders, dataset_sizes #class_names # what did you use class names for?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make(config, model_name):\n",
    "\n",
    "    # Make the model\n",
    "    weight_dict, model_dict = get_models()\n",
    "\n",
    "    #Choose model and wieghts\n",
    "    weights = weight_dict[model_name] # you need these later right as they hold the appropiate data transforamtions\n",
    "    model = model_dict[model_name].to(device)\n",
    "    # wandb.watch(model)\n",
    "\n",
    "    # new model head for for retraining\n",
    "    change_head(model_name, model, config['classes'])\n",
    "\n",
    "    # re-train all parameters\n",
    "    for param in list(model.parameters()):\n",
    "        param.requires_grad = True\n",
    "    \n",
    "    # Make the data\n",
    "    dataloaders, dataset_sizes = make_loader(batch_size=config['batch_size'],  weights = weights, attribute = config['attribute'])\n",
    "    \n",
    "    # Make the loss and optimizer\n",
    "    #criterion = nn.CrossEntropyLoss()\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(), lr=config['learning_rate'], weight_decay = config['weight_decay'], betas = config['betas'])\n",
    "\n",
    "    return model, criterion, optimizer, dataloaders, dataset_sizes #, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_log(loss, example_ct, epoch):\n",
    "    # Where the magic happens\n",
    "    # wandb.log({\"epoch\": epoch, \"loss\": loss}, step=example_ct)\n",
    "    print(f\"Loss after \" + str(example_ct).zfill(5) + f\" examples: {loss:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(images, labels, model, optimizer, criterion):\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    \n",
    "    # Forward pass ➡\n",
    "    outputs = model(images)\n",
    "    loss = criterion(outputs.squeeze(), labels)\n",
    "    \n",
    "    # Backward pass ⬅\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # Step with optimizer\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, criterion, optimizer, config):\n",
    "    # Tell wandb to watch what the model gets up to: gradients, weights, and more!\n",
    "    #wandb.watch(model, criterion, log=\"all\", log_freq=10)\n",
    "\n",
    "    # Run training and track with wandb\n",
    "    total_batches = len(loader) * config['epochs']\n",
    "    example_ct = 0  # number of examples seen\n",
    "    batch_ct = 0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for epoch in range(config['epochs']):\n",
    "        for _, (images, labels) in enumerate(loader):\n",
    "\n",
    "            loss = train_batch(images, labels, model, optimizer, criterion)\n",
    "            example_ct +=  len(images)\n",
    "            batch_ct += 1\n",
    "\n",
    "            running_loss += loss\n",
    "\n",
    "            # Report metrics every 20th batch - not running average right now\n",
    "            if ((batch_ct + 1) % 100) == 0:\n",
    "                #train_log(loss, example_ct, epoch) # this is the wand part\n",
    "                train_log(running_loss/100, example_ct, epoch)\n",
    "                running_loss = 0.0 # reset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    test_criterion = nn.MSELoss()\n",
    "\n",
    "    # Run the model on some test examples\n",
    "    with torch.no_grad():\n",
    "        #correct, total = 0, 0\n",
    "        total = 0\n",
    "        RMSE_loss = 0\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            #_, predicted = torch.max(outputs.data, 1)\n",
    "            RMSE_loss += torch.sqrt(test_criterion(outputs.squeeze().cpu(), labels.cpu()))\n",
    "\n",
    "            total += 1 #labels.size(0)\n",
    "            #correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # print(f\"Accuracy of the model on the {total} \" +\n",
    "        #       f\"test images: {100 * correct / total}%\")\n",
    "        \n",
    "        print(f\"Average RMSE of the model on the {total} \" +\n",
    "              f\"test images: {RMSE_loss / total}%\")\n",
    "\n",
    "\n",
    "        #wandb.log({\"test_rmse\": RMSE_loss / total})\n",
    "\n",
    "    # Save the model in the exchangeable ONNX format\n",
    "    #torch.onnx.export(model, images, \"model.onnx\")\n",
    "    #wandb.save(\"model.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new head: Linear(in_features=1920, out_features=1, bias=True)\n",
      "RegNet(\n",
      "  (stem): SimpleStemIN(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (trunk_output): Sequential(\n",
      "    (block1): AnyStage(\n",
      "      (block1-0): ResBottleneckBlock(\n",
      "        (proj): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 80, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (f): BottleneckTransform(\n",
      "          (a): Conv2dNormActivation(\n",
      "            (0): Conv2d(32, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (b): Conv2dNormActivation(\n",
      "            (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (c): Conv2dNormActivation(\n",
      "            (0): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activation): ReLU(inplace=True)\n",
      "      )\n",
      "      (block1-1): ResBottleneckBlock(\n",
      "        (f): BottleneckTransform(\n",
      "          (a): Conv2dNormActivation(\n",
      "            (0): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (b): Conv2dNormActivation(\n",
      "            (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (c): Conv2dNormActivation(\n",
      "            (0): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activation): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (block2): AnyStage(\n",
      "      (block2-0): ResBottleneckBlock(\n",
      "        (proj): Conv2dNormActivation(\n",
      "          (0): Conv2d(80, 240, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (f): BottleneckTransform(\n",
      "          (a): Conv2dNormActivation(\n",
      "            (0): Conv2d(80, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (b): Conv2dNormActivation(\n",
      "            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=2, bias=False)\n",
      "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (c): Conv2dNormActivation(\n",
      "            (0): Conv2d(240, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activation): ReLU(inplace=True)\n",
      "      )\n",
      "      (block2-1): ResBottleneckBlock(\n",
      "        (f): BottleneckTransform(\n",
      "          (a): Conv2dNormActivation(\n",
      "            (0): Conv2d(240, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (b): Conv2dNormActivation(\n",
      "            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
      "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (c): Conv2dNormActivation(\n",
      "            (0): Conv2d(240, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activation): ReLU(inplace=True)\n",
      "      )\n",
      "      (block2-2): ResBottleneckBlock(\n",
      "        (f): BottleneckTransform(\n",
      "          (a): Conv2dNormActivation(\n",
      "            (0): Conv2d(240, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (b): Conv2dNormActivation(\n",
      "            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
      "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (c): Conv2dNormActivation(\n",
      "            (0): Conv2d(240, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activation): ReLU(inplace=True)\n",
      "      )\n",
      "      (block2-3): ResBottleneckBlock(\n",
      "        (f): BottleneckTransform(\n",
      "          (a): Conv2dNormActivation(\n",
      "            (0): Conv2d(240, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (b): Conv2dNormActivation(\n",
      "            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
      "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (c): Conv2dNormActivation(\n",
      "            (0): Conv2d(240, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activation): ReLU(inplace=True)\n",
      "      )\n",
      "      (block2-4): ResBottleneckBlock(\n",
      "        (f): BottleneckTransform(\n",
      "          (a): Conv2dNormActivation(\n",
      "            (0): Conv2d(240, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (b): Conv2dNormActivation(\n",
      "            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
      "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (c): Conv2dNormActivation(\n",
      "            (0): Conv2d(240, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activation): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (block3): AnyStage(\n",
      "      (block3-0): ResBottleneckBlock(\n",
      "        (proj): Conv2dNormActivation(\n",
      "          (0): Conv2d(240, 720, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (f): BottleneckTransform(\n",
      "          (a): Conv2dNormActivation(\n",
      "            (0): Conv2d(240, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (b): Conv2dNormActivation(\n",
      "            (0): Conv2d(720, 720, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=6, bias=False)\n",
      "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (c): Conv2dNormActivation(\n",
      "            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activation): ReLU(inplace=True)\n",
      "      )\n",
      "      (block3-1): ResBottleneckBlock(\n",
      "        (f): BottleneckTransform(\n",
      "          (a): Conv2dNormActivation(\n",
      "            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (b): Conv2dNormActivation(\n",
      "            (0): Conv2d(720, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6, bias=False)\n",
      "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (c): Conv2dNormActivation(\n",
      "            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activation): ReLU(inplace=True)\n",
      "      )\n",
      "      (block3-2): ResBottleneckBlock(\n",
      "        (f): BottleneckTransform(\n",
      "          (a): Conv2dNormActivation(\n",
      "            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (b): Conv2dNormActivation(\n",
      "            (0): Conv2d(720, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6, bias=False)\n",
      "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (c): Conv2dNormActivation(\n",
      "            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activation): ReLU(inplace=True)\n",
      "      )\n",
      "      (block3-3): ResBottleneckBlock(\n",
      "        (f): BottleneckTransform(\n",
      "          (a): Conv2dNormActivation(\n",
      "            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (b): Conv2dNormActivation(\n",
      "            (0): Conv2d(720, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6, bias=False)\n",
      "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (c): Conv2dNormActivation(\n",
      "            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activation): ReLU(inplace=True)\n",
      "      )\n",
      "      (block3-4): ResBottleneckBlock(\n",
      "        (f): BottleneckTransform(\n",
      "          (a): Conv2dNormActivation(\n",
      "            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (b): Conv2dNormActivation(\n",
      "            (0): Conv2d(720, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6, bias=False)\n",
      "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (c): Conv2dNormActivation(\n",
      "            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activation): ReLU(inplace=True)\n",
      "      )\n",
      "      (block3-5): ResBottleneckBlock(\n",
      "        (f): BottleneckTransform(\n",
      "          (a): Conv2dNormActivation(\n",
      "            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (b): Conv2dNormActivation(\n",
      "            (0): Conv2d(720, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6, bias=False)\n",
      "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (c): Conv2dNormActivation(\n",
      "            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activation): ReLU(inplace=True)\n",
      "      )\n",
      "      (block3-6): ResBottleneckBlock(\n",
      "        (f): BottleneckTransform(\n",
      "          (a): Conv2dNormActivation(\n",
      "            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (b): Conv2dNormActivation(\n",
      "            (0): Conv2d(720, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6, bias=False)\n",
      "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (c): Conv2dNormActivation(\n",
      "            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activation): ReLU(inplace=True)\n",
      "      )\n",
      "      (block3-7): ResBottleneckBlock(\n",
      "        (f): BottleneckTransform(\n",
      "          (a): Conv2dNormActivation(\n",
      "            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (b): Conv2dNormActivation(\n",
      "            (0): Conv2d(720, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6, bias=False)\n",
      "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (c): Conv2dNormActivation(\n",
      "            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activation): ReLU(inplace=True)\n",
      "      )\n",
      "      (block3-8): ResBottleneckBlock(\n",
      "        (f): BottleneckTransform(\n",
      "          (a): Conv2dNormActivation(\n",
      "            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (b): Conv2dNormActivation(\n",
      "            (0): Conv2d(720, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6, bias=False)\n",
      "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (c): Conv2dNormActivation(\n",
      "            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activation): ReLU(inplace=True)\n",
      "      )\n",
      "      (block3-9): ResBottleneckBlock(\n",
      "        (f): BottleneckTransform(\n",
      "          (a): Conv2dNormActivation(\n",
      "            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (b): Conv2dNormActivation(\n",
      "            (0): Conv2d(720, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6, bias=False)\n",
      "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (c): Conv2dNormActivation(\n",
      "            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activation): ReLU(inplace=True)\n",
      "      )\n",
      "      (block3-10): ResBottleneckBlock(\n",
      "        (f): BottleneckTransform(\n",
      "          (a): Conv2dNormActivation(\n",
      "            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (b): Conv2dNormActivation(\n",
      "            (0): Conv2d(720, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6, bias=False)\n",
      "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (c): Conv2dNormActivation(\n",
      "            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activation): ReLU(inplace=True)\n",
      "      )\n",
      "      (block3-11): ResBottleneckBlock(\n",
      "        (f): BottleneckTransform(\n",
      "          (a): Conv2dNormActivation(\n",
      "            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (b): Conv2dNormActivation(\n",
      "            (0): Conv2d(720, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6, bias=False)\n",
      "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (c): Conv2dNormActivation(\n",
      "            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activation): ReLU(inplace=True)\n",
      "      )\n",
      "      (block3-12): ResBottleneckBlock(\n",
      "        (f): BottleneckTransform(\n",
      "          (a): Conv2dNormActivation(\n",
      "            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (b): Conv2dNormActivation(\n",
      "            (0): Conv2d(720, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6, bias=False)\n",
      "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (c): Conv2dNormActivation(\n",
      "            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activation): ReLU(inplace=True)\n",
      "      )\n",
      "      (block3-13): ResBottleneckBlock(\n",
      "        (f): BottleneckTransform(\n",
      "          (a): Conv2dNormActivation(\n",
      "            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (b): Conv2dNormActivation(\n",
      "            (0): Conv2d(720, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6, bias=False)\n",
      "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (c): Conv2dNormActivation(\n",
      "            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activation): ReLU(inplace=True)\n",
      "      )\n",
      "      (block3-14): ResBottleneckBlock(\n",
      "        (f): BottleneckTransform(\n",
      "          (a): Conv2dNormActivation(\n",
      "            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (b): Conv2dNormActivation(\n",
      "            (0): Conv2d(720, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6, bias=False)\n",
      "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (c): Conv2dNormActivation(\n",
      "            (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activation): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (block4): AnyStage(\n",
      "      (block4-0): ResBottleneckBlock(\n",
      "        (proj): Conv2dNormActivation(\n",
      "          (0): Conv2d(720, 1920, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (f): BottleneckTransform(\n",
      "          (a): Conv2dNormActivation(\n",
      "            (0): Conv2d(720, 1920, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (b): Conv2dNormActivation(\n",
      "            (0): Conv2d(1920, 1920, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
      "            (1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (c): Conv2dNormActivation(\n",
      "            (0): Conv2d(1920, 1920, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activation): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=1920, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# access all HPs through wandb.config, so logging matches execution!\n",
    "config = hyperparameters\n",
    "\n",
    "model_name = config['model_name']\n",
    "\n",
    "# make the model, data, and optimization problem\n",
    "model, criterion, optimizer, dataloaders, dataset_sizes = make(config, model_name)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # and use them to train the model\n",
    "# train(model, dataloaders['train'], criterion, optimizer, config)\n",
    "\n",
    "# # and test its final performance\n",
    "# test(model, dataloaders['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch RMSE loss: 1.0530973672866821\n",
      "Batch RMSE loss: 1.041982889175415\n",
      "Batch RMSE loss: 1.1272201538085938\n",
      "Batch RMSE loss: 0.6610047817230225\n",
      "Batch RMSE loss: 0.9385876059532166\n",
      "Batch RMSE loss: 0.6299359798431396\n",
      "Batch RMSE loss: 1.1221593618392944\n",
      "Batch RMSE loss: 1.3915281295776367\n",
      "Batch RMSE loss: 1.025121808052063\n",
      "Batch RMSE loss: 0.5970933437347412\n",
      "Batch RMSE loss: 1.4491084814071655\n",
      "Batch RMSE loss: 0.8849812746047974\n",
      "Batch RMSE loss: 0.7312242388725281\n",
      "Batch RMSE loss: 0.675737738609314\n",
      "Batch RMSE loss: 0.9315090775489807\n",
      "Batch RMSE loss: 0.7649460434913635\n",
      "Batch RMSE loss: 0.8738184571266174\n",
      "Batch RMSE loss: 0.7086728811264038\n",
      "Batch RMSE loss: 0.7295205593109131\n",
      "Batch RMSE loss: 0.9991548657417297\n",
      "Batch RMSE loss: 0.744766891002655\n",
      "Batch RMSE loss: 1.5776572227478027\n",
      "Average RMSE of the model on the 22 test images: 0.9390376806259155%\n",
      "alt version: 0.9390376887538217\n"
     ]
    }
   ],
   "source": [
    "# BS = 4\n",
    "model.eval()\n",
    "\n",
    "test_criterion = nn.MSELoss()\n",
    "\n",
    "total = 0\n",
    "RMSE_loss_running = 0\n",
    "RMSE_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in dataloaders['test']:\n",
    "        y = model(images)\n",
    "        torch.sqrt(test_criterion(y.squeeze(), labels))\n",
    "\n",
    "        #_, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        RMSE_loss = torch.sqrt(test_criterion(y.squeeze(), labels))\n",
    "        RMSE_list.append(RMSE_loss.detach().numpy().item())\n",
    "        RMSE_loss_running += RMSE_loss\n",
    "        \n",
    "        print(f'Batch RMSE loss: {RMSE_loss}')\n",
    "        \n",
    "        total += 1 # labels.size(0) #  1\n",
    "\n",
    "    print(f\"Average RMSE of the model on the {total} \" + f\"test images: {RMSE_loss_running / total}%\")\n",
    "    print(f\"alt version: {np.array(RMSE_list).mean()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch RMSE loss: 0.6822541952133179\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch RMSE loss: 1.0091129541397095\n",
      "Batch RMSE loss: 0.9891952872276306\n",
      "Batch RMSE loss: 1.277721881866455\n",
      "Batch RMSE loss: 1.022247552871704\n",
      "Batch RMSE loss: 0.930595874786377\n",
      "Batch RMSE loss: 0.744383692741394\n",
      "Batch RMSE loss: 0.9413062334060669\n",
      "Batch RMSE loss: 0.6356397271156311\n",
      "Batch RMSE loss: 1.377557396888733\n",
      "Batch RMSE loss: 0.5771723389625549\n",
      "Batch RMSE loss: 0.6576986908912659\n",
      "Batch RMSE loss: 1.154015064239502\n",
      "Batch RMSE loss: 1.0379843711853027\n",
      "Batch RMSE loss: 0.3965778350830078\n",
      "Batch RMSE loss: 0.8038842082023621\n",
      "Batch RMSE loss: 0.8570382595062256\n",
      "Batch RMSE loss: 0.9580329060554504\n",
      "Batch RMSE loss: 0.9573437571525574\n",
      "Batch RMSE loss: 0.8930890560150146\n",
      "Batch RMSE loss: 0.9257214069366455\n",
      "Batch RMSE loss: 1.5151762962341309\n",
      "Batch RMSE loss: 0.5565876364707947\n",
      "Average RMSE of the model on the 22 test images: 0.9190038442611694%\n",
      "alt version: 0.9190037467262961\n"
     ]
    }
   ],
   "source": [
    "# BS = 8\n",
    "model.eval()\n",
    "\n",
    "test_criterion = nn.MSELoss()\n",
    "\n",
    "total = 0\n",
    "RMSE_loss_running = 0\n",
    "RMSE_list = []\n",
    "\n",
    "for images, labels in dataloaders['test']:\n",
    "    y = model(images)\n",
    "    torch.sqrt(test_criterion(y.squeeze(), labels))\n",
    "\n",
    "    #_, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "    RMSE_loss = torch.sqrt(test_criterion(y.squeeze(), labels))\n",
    "    RMSE_list.append(RMSE_loss.detach().numpy().item())\n",
    "    RMSE_loss_running += RMSE_loss\n",
    "    \n",
    "    print(f'Batch RMSE loss: {RMSE_loss}')\n",
    "    \n",
    "    total += 1 # labels.size(0) #  1\n",
    "\n",
    "print(f\"Average RMSE of the model on the {total} \" + f\"test images: {RMSE_loss_running / total}%\")\n",
    "print(f\"alt version: {np.array(RMSE_list).mean()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n"
     ]
    }
   ],
   "source": [
    "epochs = 64\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    if epoch == epochs-1:\n",
    "        print(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(RMSE_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4013563394546509"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE_loss.detach().numpy().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMSE of the model on the 43 test images: 0.9227243661880493%\n"
     ]
    }
   ],
   "source": [
    "# BS = 4\n",
    "model.eval()\n",
    "\n",
    "test_criterion = nn.MSELoss()\n",
    "\n",
    "total = 0\n",
    "RMSE_loss = 0\n",
    "\n",
    "for images, labels in dataloaders['test']:\n",
    "    y = model(images)\n",
    "    torch.sqrt(test_criterion(y.squeeze(), labels))\n",
    "\n",
    "    #_, predicted = torch.max(outputs.data, 1)\n",
    "    RMSE_loss += torch.sqrt(test_criterion(y.squeeze(), labels))\n",
    "    \n",
    "    \n",
    "    total += 1 #labels.size(0) #  1\n",
    "\n",
    "print(f\"Average RMSE of the model on the {total} \" + f\"test images: {RMSE_loss / total}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ra_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "598a7b5fc01858df36cc1c0a4eb38eebc98bc1606c00c65496daa70f494bd19d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
