{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "3.8.13 (default, Mar 28 2022, 11:38:47) \n",
      "[GCC 7.5.0]\n",
      "1.12.1\n",
      "0.13.1\n"
     ]
    }
   ],
   "source": [
    "# use torch_2022\n",
    "\n",
    "import numpy as np\n",
    "#import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import sys\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.io import read_image\n",
    "\n",
    "\n",
    "# models - you do need the weights for the transformations.\n",
    "from torchvision.models import convnext_tiny, ConvNeXt_Tiny_Weights\n",
    "from torchvision.models import efficientnet_v2_s, EfficientNet_V2_S_Weights\n",
    "from torchvision.models import regnet_x_8gf, RegNet_X_8GF_Weights\n",
    "from torchvision.models import swin_t, Swin_T_Weights\n",
    "from torchvision.models import wide_resnet50_2, Wide_ResNet50_2_Weights\n",
    "\n",
    "#import wandb\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)\n",
    "print(sys.version)\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a loop: \n",
    "\n",
    "pseudo python code\n",
    "\n",
    "\n",
    "For each model:\n",
    "    For each fature:\n",
    "        feature_list = []\n",
    "        img_list = []\n",
    "        for img:\n",
    "            score = model(img)\n",
    "\n",
    "            feature_list.add(score)\n",
    "            img_list.add(img)\n",
    "\n",
    "        df = pd.Dataframe({feature : feature_list, 'img_id' : img_list})\n",
    "        df.to_pkl(.../model_feature.pkl)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW YOU DO NOT NEED TRAIN; TEST OR VAL AS EVERYTHING IS ALL IMAGES AND NO EXTRA TRANSFORAMTIONS:\n",
    "# ALSO you do not have labels\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, attribute_dict, transform=None):\n",
    "\n",
    "\n",
    "        self.img_id = attribute_dict['img'] # img_id + .jpg\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_id)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.img_id[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_id)\n",
    "        image = read_image(img_path)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, img_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_head(model_name, model, num_classes):\n",
    "\n",
    "    if model_name == 'convnext_tiny':\n",
    "        model.classifier[2] = nn.Linear(model.classifier[2].in_features, num_classes, bias=False).to(device)\n",
    "        #print(f'new head: {model.classifier[2]}')\n",
    "\n",
    "    elif model_name == 'efficientnet_v2_s':\n",
    "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes, bias=False).to(device)\n",
    "        #print(f'new head: {model.classifier[1]}')\n",
    "\n",
    "    elif model_name == 'regnet_x_8gf':\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes, bias=False).to(device)\n",
    "        #print(f'new head: {model.fc}')\n",
    "\n",
    "    elif model_name == 'swin_t':\n",
    "        model.head = nn.Linear(model.head.in_features, num_classes, bias=False).to(device)\n",
    "        #print(f'new head: {model.head}')\n",
    "\n",
    "    elif model_name == 'wide_resnet50_2':\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes, bias=False).to(device)\n",
    "        #print(f'new head: {model.fc}')\n",
    "\n",
    "    elif model_name == 'squeezenet1_1' :\n",
    "        model.classifier[1] = nn.Conv2d(model.classifier[1].in_channels, num_classes, kernel_size=(1, 1), stride=(1, 1), bias=False).to(device)\n",
    "        #print(f'new head: {model.classifier[1]}')\n",
    "\n",
    "    elif model_name == 'shufflenet_v2_x0_5' :\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes, bias=False).to(device)\n",
    "        #print(f'new head: {model.fc}')\n",
    "\n",
    "    elif model_name == 'mnasnet0_5' :\n",
    "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes, bias=False).to(device)\n",
    "        #print(f'new head: {model.classifier[1]}')    \n",
    "\n",
    "    elif model_name == 'mobilenet_v3_small' :\n",
    "        model.classifier[3] = nn.Linear(model.classifier[3].in_features, num_classes, bias=False).to(device)\n",
    "        #print(f'new head: {model.classifier[3]}')\n",
    "\n",
    "    else:\n",
    "        print('Unddefined model name...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JUST LOAD PRETRAINED MODEL\n",
    "\n",
    "def get_model(hyperparameters):\n",
    "\n",
    "    weight_dict = {'convnext_tiny': ConvNeXt_Tiny_Weights.DEFAULT,\n",
    "                'efficientnet_v2_s' : EfficientNet_V2_S_Weights.DEFAULT,\n",
    "                'regnet_x_8gf' : RegNet_X_8GF_Weights.DEFAULT,\n",
    "                'swin_t' : Swin_T_Weights.DEFAULT,\n",
    "                'wide_resnet50_2' : Wide_ResNet50_2_Weights.DEFAULT}\n",
    "\n",
    "    model_dict = {'convnext_tiny': convnext_tiny(weights = weight_dict['convnext_tiny']).to(device),\n",
    "                'efficientnet_v2_s' : efficientnet_v2_s(weights = weight_dict['efficientnet_v2_s']).to(device),\n",
    "                'regnet_x_8gf' : regnet_x_8gf(weights = weight_dict['regnet_x_8gf']).to(device),\n",
    "                'swin_t' : swin_t(weights = weight_dict['swin_t']).to(device),\n",
    "                'wide_resnet50_2' : wide_resnet50_2(weights = weight_dict['wide_resnet50_2']).to(device)}\n",
    "\n",
    "    # model_name = hyperparameters['model_name']\n",
    "\n",
    "    model_name = hyperparameters['model_name']\n",
    "    attribute = hyperparameters['attribute']\n",
    "\n",
    "    pt_model_dir = \"/home/simon/Documents/computerome/done_RA_models/\"\n",
    "    pt_model_name = f'{model_name}_{attribute}'\n",
    "\n",
    "    model = model_dict[model_name]\n",
    "    change_head(model_name, model, 1)\n",
    "    \n",
    "    model.load_state_dict(torch.load(f'{pt_model_dir}{pt_model_name}_SD.pth', map_location=torch.device('cpu'))) #!!!! Remove or change map_location\n",
    "    model.eval()\n",
    "\n",
    "    return(model, weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loader\n",
    "def make_loader(batch_size, weights, attribute_dict):\n",
    "\n",
    "    data_transform = transforms.Compose([weights.transforms()])\n",
    "\n",
    "    # img_dir = '/media/simon/Seagate Expansion Drive/images_spanner' #local\n",
    "    img_dir = '/home/projects/ku_00017/data/raw/bodies/images_spanner' # computerome\n",
    "\n",
    "    image_dataset = CustomImageDataset(img_dir, attribute_dict, transform=data_transform)\n",
    "    dataloader = DataLoader(image_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    dataset_size = len(image_dataset)\n",
    "\n",
    "    return dataloader, dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make(hyperparameters):\n",
    "\n",
    "    # Make the model\n",
    "    model, weight_dict = get_model(hyperparameters)\n",
    "\n",
    "    model_name = hyperparameters['model_name']\n",
    "\n",
    "    #Choose model and wieghts\n",
    "    weights = weight_dict[model_name] # you need these later right as they hold the appropiate data transforamtions\n",
    "    model = model.to(device)\n",
    "    # wandb.watch(model)\n",
    "    \n",
    "    # is this an ok place? \n",
    "    #dict_dir = '/home/simon/Documents/Bodies/data/RA/dfs/' # change to computerome location\n",
    "    dict_dir = '/home/projects/ku_00017/data/raw/bodies/RA_annotations/' # computerome\n",
    "\n",
    "    with open(f'{dict_dir}ra_ens_annotated_dict.pkl', 'rb') as file:\n",
    "        attribute_dict = pickle.load(file)\n",
    "\n",
    "    # Make the data\n",
    "    dataloader, dataset_size = make_loader(batch_size=hyperparameters['batch_size'],  weights = weights, attribute_dict = attribute_dict)\n",
    "\n",
    "    return model, dataloader, dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, dataloader):\n",
    "    model.eval() # one more time why not.\n",
    "\n",
    "    image_list = []\n",
    "    score_list = []\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    # Run the model on some test examples\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for images, img_id in dataloader:\n",
    "                \n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "\n",
    "            image_list += list(img_id)\n",
    "            score_list += list(outputs.squeeze().detach().cpu().numpy())\n",
    "            \n",
    "    return(image_list, score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def the_loop():\n",
    "    relevant_models = ['convnext_tiny', 'efficientnet_v2_s', 'swin_t']\n",
    "\n",
    "    attributes = ['all_negative_emotions_t1', 'all_mass_protest', 'all_militarized',\n",
    "                'all_urban', 'all_negative_emotions_t2', 'all_privat', 'all_public', \n",
    "                'all_rural', 'all_formal', 'all_damaged_property']\n",
    "\n",
    "\n",
    "    data_dir = '/home/projects/ku_00017/data/generated/bodies/ra_outputs/'\n",
    "\n",
    "    for model_name in relevant_models:\n",
    "        \n",
    "        score_dict = {}\n",
    "        \n",
    "        for attribute in attributes:\n",
    "\n",
    "            hyperparameters = {\"model_name\" : model_name, \"attribute\" : attribute, \"batch_size\": 32}\n",
    "            model, dataloader, dataset_size = make(hyperparameters)\n",
    "            image_list, score_list = predict(model, dataloader)\n",
    "\n",
    "            score_dict['attribute_score'] = score_list,\n",
    "            score_dict['attribute_id'] = image_list # not sure you get the rigth order so this is just for debug really.\n",
    "\n",
    "        dict_name = f'{model_name}_score_dict.pkl'\n",
    "\n",
    "        with open(f'{data_dir}{dict_name}', 'wb') as file:\n",
    "            pickle.dump(score_dict, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('torch_2022')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c861190dc1f6bbb148ba5b7a2d7833f4e7542a6e06a051c902737eff7c357b5f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
