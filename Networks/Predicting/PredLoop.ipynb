{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "3.8.13 (default, Mar 28 2022, 11:38:47) \n",
      "[GCC 7.5.0]\n",
      "1.12.1\n",
      "0.13.1\n"
     ]
    }
   ],
   "source": [
    "# use torch_2022\n",
    "\n",
    "import numpy as np\n",
    "#import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import sys\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.io import read_image\n",
    "\n",
    "\n",
    "# models - you do need the weights for the transformations.\n",
    "from torchvision.models import convnext_tiny, ConvNeXt_Tiny_Weights\n",
    "from torchvision.models import efficientnet_v2_s, EfficientNet_V2_S_Weights\n",
    "from torchvision.models import regnet_x_8gf, RegNet_X_8GF_Weights\n",
    "from torchvision.models import swin_t, Swin_T_Weights\n",
    "from torchvision.models import wide_resnet50_2, Wide_ResNet50_2_Weights\n",
    "\n",
    "#import wandb\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)\n",
    "print(sys.version)\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a loop: \n",
    "\n",
    "pseudo python code\n",
    "\n",
    "\n",
    "For each model:\n",
    "    For each fature:\n",
    "        feature_list = []\n",
    "        img_list = []\n",
    "        for img:\n",
    "            score = model(img)\n",
    "\n",
    "            feature_list.add(score)\n",
    "            img_list.add(img)\n",
    "\n",
    "        df = pd.Dataframe({feature : feature_list, 'img_id' : img_list})\n",
    "        df.to_pkl(.../model_feature.pkl)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# BUT HERE IT SHOULD JUST BE LOAD A PRETRAINED MODEL!!!!!!! # ---------------------------------------\n",
    "\n",
    "#should be terminal inputs:\n",
    "\n",
    "# choose one model\n",
    "model_name = 'convnext_tiny' # last block is called \"classifier\" \n",
    "# model_name = 'efficientnet_v2_s' # last block is called \"classifier\" \n",
    "# model_name = 'regnet_x_8gf' # last block is called \"fc\" \n",
    "# model_name = 'swin_t'  # last block is called \"head\" \n",
    "# model_name = 'wide_resnet50_2'  # last block is called \"fc\" \n",
    "\n",
    "attribute = 'all_mass_protest' #\n",
    "\n",
    "hyperparameters = {\n",
    "\"model_name\" : model_name,\n",
    "\"attribute\" : attribute,\n",
    "\"batch_size\" : 32}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW YOU DO NOT NEED TRAIN; TEST OR VAL AS EVERYTHING IS ALL IMAGES AND NO EXTRA TRANSFORAMTIONS:\n",
    "# ALSO you do not have labels\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform=None):\n",
    "\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels[idx, 0])\n",
    "        image = read_image(img_path)\n",
    "        label = None\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_head(model_name, model, num_classes):\n",
    "\n",
    "    if model_name == 'convnext_tiny':\n",
    "        model.classifier[2] = nn.Linear(model.classifier[2].in_features, num_classes, bias=False).to(device)\n",
    "        print(f'new head: {model.classifier[2]}')\n",
    "\n",
    "    elif model_name == 'efficientnet_v2_s':\n",
    "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes, bias=False).to(device)\n",
    "        print(f'new head: {model.classifier[1]}')\n",
    "\n",
    "    elif model_name == 'regnet_x_8gf':\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes, bias=False).to(device)\n",
    "        print(f'new head: {model.fc}')\n",
    "\n",
    "    elif model_name == 'swin_t':\n",
    "        model.head = nn.Linear(model.head.in_features, num_classes, bias=False).to(device)\n",
    "        print(f'new head: {model.head}')\n",
    "\n",
    "    elif model_name == 'wide_resnet50_2':\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes, bias=False).to(device)\n",
    "        print(f'new head: {model.fc}')\n",
    "\n",
    "    elif model_name == 'squeezenet1_1' :\n",
    "        model.classifier[1] = nn.Conv2d(model.classifier[1].in_channels, num_classes, kernel_size=(1, 1), stride=(1, 1), bias=False).to(device)\n",
    "        print(f'new head: {model.classifier[1]}')\n",
    "\n",
    "    elif model_name == 'shufflenet_v2_x0_5' :\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes, bias=False).to(device)\n",
    "        print(f'new head: {model.fc}')\n",
    "\n",
    "    elif model_name == 'mnasnet0_5' :\n",
    "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes, bias=False).to(device)\n",
    "        print(f'new head: {model.classifier[1]}')    \n",
    "\n",
    "    elif model_name == 'mobilenet_v3_small' :\n",
    "        model.classifier[3] = nn.Linear(model.classifier[3].in_features, num_classes, bias=False).to(device)\n",
    "        print(f'new head: {model.classifier[3]}')\n",
    "\n",
    "    else:\n",
    "        print('Unddefined model name...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/simon/Documents/Bodies/data/done_RA_models/convnext_tiny_all_mass_protest.pth\n"
     ]
    }
   ],
   "source": [
    "model_dir = \"/home/simon/Documents/Bodies/data/done_RA_models/\"\n",
    "model_name = f'{hyperparameters[\"model_name\"]}_{hyperparameters[\"attribute\"]}.pth'\n",
    "model_path = f'{model_dir}{model_name}' \n",
    "\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JUST LOAD PRETRAINED MODEL\n",
    "\n",
    "def get_model(hyperparameters):\n",
    "\n",
    "    weight_dict = {'convnext_tiny': ConvNeXt_Tiny_Weights.DEFAULT,\n",
    "                'efficientnet_v2_s' : EfficientNet_V2_S_Weights.DEFAULT,\n",
    "                'regnet_x_8gf' : RegNet_X_8GF_Weights.DEFAULT,\n",
    "                'swin_t' : Swin_T_Weights.DEFAULT,\n",
    "                'wide_resnet50_2' : Wide_ResNet50_2_Weights.DEFAULT}\n",
    "\n",
    "    model_dict = {'convnext_tiny': convnext_tiny(weights = weight_dict['convnext_tiny']).to(device),\n",
    "                'efficientnet_v2_s' : efficientnet_v2_s(weights = weight_dict['efficientnet_v2_s']).to(device),\n",
    "                'regnet_x_8gf' : regnet_x_8gf(weights = weight_dict['regnet_x_8gf']).to(device),\n",
    "                'swin_t' : swin_t(weights = weight_dict['swin_t']).to(device),\n",
    "                'wide_resnet50_2' : wide_resnet50_2(weights = weight_dict['wide_resnet50_2']).to(device)}\n",
    "\n",
    "    # model_name = hyperparameters['model_name']\n",
    "\n",
    "    model_dir = \"/home/simon/Documents/computerome/done_RA_models/\"\n",
    "    model_name = f'{hyperparameters[\"model_name\"]}_{hyperparameters[\"attribute\"]}'\n",
    "    model_path = f'{model_dir}{model_name}'  # .pth\n",
    "\n",
    "    #model = torch.load(model_path)\n",
    "    #model.eval()\n",
    "\n",
    "    # model_SD_dir = \"/home/simon/Documents/Bodies/data/done_RA_models/\"\n",
    "    # model_SD_name = f\"{hyperparameters['model_name']}_{hyperparameters['attribute']}\"\n",
    "\n",
    "    model = model_dict['convnext_tiny']\n",
    "    change_head('convnext_tiny', model, 1)\n",
    "    \n",
    "    model.load_state_dict(torch.load(f'{model_dir}{model_name}_SD.pth', map_location=torch.device('cpu')))\n",
    "    model.eval()\n",
    "\n",
    "    return(model, weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new head: Linear(in_features=768, out_features=1, bias=False)\n"
     ]
    }
   ],
   "source": [
    "model, weight_dict = get_model(hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loader\n",
    "def make_loader(batch_size, weights, attribute):\n",
    "\n",
    "    data_transform = transforms.Compose([weights.transforms()])\n",
    "\n",
    "    dict_dir = '/home/simon/Documents/Bodies/data/RA/dfs/' #local\n",
    "    img_dir = '/media/simon/Seagate Expansion Drive/images_spanner' #local\n",
    "    \n",
    "    image_dataset = CustomImageDataset(attribute, img_dir, transform=data_transform)\n",
    "    dataloader = DataLoader(image_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    dataset_size = len(image_dataset)\n",
    "\n",
    "    return dataloader, dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make(config, model_name):\n",
    "\n",
    "    # JUST LOAD THE .pth FILE but you will still need the wieghts from the original model for the base transformations\n",
    "\n",
    "    # Make the model\n",
    "    weight_dict, model_dict = get_models()\n",
    "\n",
    "    #Choose model and wieghts\n",
    "    weights = weight_dict[model_name] # you need these later right as they hold the appropiate data transforamtions\n",
    "    model = model_dict[model_name].to(device)\n",
    "    # wandb.watch(model)\n",
    "\n",
    "    # NO!\n",
    "    # new model head for for retraining\n",
    "    change_head(model_name, model, config['classes'])\n",
    "\n",
    "    # NO!\n",
    "    # re-train all parameters\n",
    "    for param in list(model.parameters()):\n",
    "        param.requires_grad = True\n",
    "    \n",
    "    # Make the data\n",
    "    dataloaders, dataset_sizes = make_loader(batch_size=config['batch_size'],  weights = weights, attribute = config['attribute'])\n",
    "    \n",
    "    # NO NEED!\n",
    "    # Make the loss and optimizer\n",
    "    #criterion = nn.CrossEntropyLoss()\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(), lr=config['learning_rate'], weight_decay = config['weight_decay'], betas = config['betas'])\n",
    "\n",
    "    return model, criterion, optimizer, dataloaders, dataset_sizes #, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDK\n",
    "\n",
    "def train_log(loss, example_ct, epoch):\n",
    "    # Where the magic happens\n",
    "    # wandb.log({\"epoch\": epoch, \"loss\": loss}, step=example_ct)\n",
    "    print(f\"Loss after \" + str(example_ct).zfill(5) + f\" examples: {loss:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO NEED!!!!\n",
    "\n",
    "def train_batch(images, labels, model, optimizer, criterion):\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    \n",
    "    # Forward pass ➡\n",
    "    outputs = model(images)\n",
    "    loss = criterion(outputs.squeeze(), labels)\n",
    "    \n",
    "    # Backward pass ⬅\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # Step with optimizer\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO NEED!!!\n",
    "\n",
    "def train(model, loader, criterion, optimizer, config):\n",
    "    # Tell wandb to watch what the model gets up to: gradients, weights, and more!\n",
    "    #wandb.watch(model, criterion, log=\"all\", log_freq=10)\n",
    "\n",
    "    # Run training and track with wandb\n",
    "    total_batches = len(loader) * config['epochs']\n",
    "    example_ct = 0  # number of examples seen\n",
    "    batch_ct = 0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for epoch in range(config['epochs']):\n",
    "        for _, (images, labels) in enumerate(loader):\n",
    "\n",
    "            loss = train_batch(images, labels, model, optimizer, criterion)\n",
    "            example_ct +=  len(images)\n",
    "            batch_ct += 1\n",
    "\n",
    "            running_loss += loss\n",
    "\n",
    "            # Report metrics every 20th batch - not running average right now\n",
    "            if ((batch_ct + 1) % 100) == 0:\n",
    "                #train_log(loss, example_ct, epoch) # this is the wand part\n",
    "                train_log(running_loss/100, example_ct, epoch)\n",
    "                running_loss = 0.0 # reset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS THE CORE NOW! Save each out put with the image id. - until now you have not used the image id..\n",
    "\n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    test_criterion = nn.MSELoss()\n",
    "\n",
    "    # Run the model on some test examples\n",
    "    with torch.no_grad():\n",
    "        #correct, total = 0, 0\n",
    "        total = 0\n",
    "        RMSE_loss = 0\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            #_, predicted = torch.max(outputs.data, 1)\n",
    "            RMSE_loss += torch.sqrt(test_criterion(outputs.squeeze().cpu(), labels.cpu()))\n",
    "\n",
    "            total += 1 #labels.size(0)\n",
    "            #correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # print(f\"Accuracy of the model on the {total} \" +\n",
    "        #       f\"test images: {100 * correct / total}%\")\n",
    "        \n",
    "        print(f\"Average RMSE of the model on the {total} \" +\n",
    "              f\"test images: {RMSE_loss / total}%\")\n",
    "\n",
    "\n",
    "        #wandb.log({\"test_rmse\": RMSE_loss / total})\n",
    "\n",
    "    # Save the model in the exchangeable ONNX format\n",
    "    #torch.onnx.export(model, images, \"model.onnx\")\n",
    "    #wandb.save(\"model.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access all HPs through wandb.config, so logging matches execution!\n",
    "config = hyperparameters\n",
    "\n",
    "model_name = config['model_name']\n",
    "\n",
    "# make the model, data, and optimization problem\n",
    "model, criterion, optimizer, dataloaders, dataset_sizes = make(config, model_name)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # and use them to train the model\n",
    "# train(model, dataloaders['train'], criterion, optimizer, config)\n",
    "\n",
    "# # and test its final performance\n",
    "# test(model, dataloaders['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('torch_2022')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c861190dc1f6bbb148ba5b7a2d7833f4e7542a6e06a051c902737eff7c357b5f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
