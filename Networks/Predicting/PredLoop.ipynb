{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "3.8.13 (default, Mar 28 2022, 11:38:47) \n",
      "[GCC 7.5.0]\n",
      "1.12.1\n",
      "0.13.1\n"
     ]
    }
   ],
   "source": [
    "# use torch_2022\n",
    "\n",
    "import numpy as np\n",
    "#import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import sys\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.io import read_image\n",
    "\n",
    "\n",
    "# models - you do need the weights for the transformations.\n",
    "from torchvision.models import convnext_tiny, ConvNeXt_Tiny_Weights\n",
    "from torchvision.models import efficientnet_v2_s, EfficientNet_V2_S_Weights\n",
    "from torchvision.models import regnet_x_8gf, RegNet_X_8GF_Weights\n",
    "from torchvision.models import swin_t, Swin_T_Weights\n",
    "from torchvision.models import wide_resnet50_2, Wide_ResNet50_2_Weights\n",
    "\n",
    "#import wandb\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)\n",
    "print(sys.version)\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a loop: \n",
    "\n",
    "pseudo python code\n",
    "\n",
    "\n",
    "For each model:\n",
    "    For each fature:\n",
    "        feature_list = []\n",
    "        img_list = []\n",
    "        for img:\n",
    "            score = model(img)\n",
    "\n",
    "            feature_list.add(score)\n",
    "            img_list.add(img)\n",
    "\n",
    "        df = pd.Dataframe({feature : feature_list, 'img_id' : img_list})\n",
    "        df.to_pkl(.../model_feature.pkl)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# BUT HERE IT SHOULD JUST BE LOAD A PRETRAINED MODEL!!!!!!! # ---------------------------------------\n",
    "\n",
    "#should be terminal inputs:\n",
    "\n",
    "# choose one model\n",
    "model_name = 'convnext_tiny' # last block is called \"classifier\" \n",
    "# model_name = 'efficientnet_v2_s' # last block is called \"classifier\" \n",
    "# model_name = 'regnet_x_8gf' # last block is called \"fc\" \n",
    "# model_name = 'swin_t'  # last block is called \"head\" \n",
    "# model_name = 'wide_resnet50_2'  # last block is called \"fc\" \n",
    "\n",
    "attribute = 'all_mass_protest' #\n",
    "\n",
    "hyperparameters = {\n",
    "\"model_name\" : model_name,\n",
    "\"attribute\" : attribute,\n",
    "\"batch_size\" : 32}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW YOU DO NOT NEED TRAIN; TEST OR VAL AS EVERYTHING IS ALL IMAGES AND NO EXTRA TRANSFORAMTIONS:\n",
    "# ALSO you do not have labels\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, attribute_dict, transform=None):\n",
    "\n",
    "\n",
    "        self.img_id = attribute_dict['img'] # img_id + .jpg\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_id)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.img_id[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_id)\n",
    "        image = read_image(img_path)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, img_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_head(model_name, model, num_classes):\n",
    "\n",
    "    if model_name == 'convnext_tiny':\n",
    "        model.classifier[2] = nn.Linear(model.classifier[2].in_features, num_classes, bias=False).to(device)\n",
    "        #print(f'new head: {model.classifier[2]}')\n",
    "\n",
    "    elif model_name == 'efficientnet_v2_s':\n",
    "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes, bias=False).to(device)\n",
    "        #print(f'new head: {model.classifier[1]}')\n",
    "\n",
    "    elif model_name == 'regnet_x_8gf':\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes, bias=False).to(device)\n",
    "        #print(f'new head: {model.fc}')\n",
    "\n",
    "    elif model_name == 'swin_t':\n",
    "        model.head = nn.Linear(model.head.in_features, num_classes, bias=False).to(device)\n",
    "        #print(f'new head: {model.head}')\n",
    "\n",
    "    elif model_name == 'wide_resnet50_2':\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes, bias=False).to(device)\n",
    "        #print(f'new head: {model.fc}')\n",
    "\n",
    "    elif model_name == 'squeezenet1_1' :\n",
    "        model.classifier[1] = nn.Conv2d(model.classifier[1].in_channels, num_classes, kernel_size=(1, 1), stride=(1, 1), bias=False).to(device)\n",
    "        #print(f'new head: {model.classifier[1]}')\n",
    "\n",
    "    elif model_name == 'shufflenet_v2_x0_5' :\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes, bias=False).to(device)\n",
    "        #print(f'new head: {model.fc}')\n",
    "\n",
    "    elif model_name == 'mnasnet0_5' :\n",
    "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes, bias=False).to(device)\n",
    "        #print(f'new head: {model.classifier[1]}')    \n",
    "\n",
    "    elif model_name == 'mobilenet_v3_small' :\n",
    "        model.classifier[3] = nn.Linear(model.classifier[3].in_features, num_classes, bias=False).to(device)\n",
    "        #print(f'new head: {model.classifier[3]}')\n",
    "\n",
    "    else:\n",
    "        print('Unddefined model name...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JUST LOAD PRETRAINED MODEL\n",
    "\n",
    "def get_model(hyperparameters):\n",
    "\n",
    "    weight_dict = {'convnext_tiny': ConvNeXt_Tiny_Weights.DEFAULT,\n",
    "                'efficientnet_v2_s' : EfficientNet_V2_S_Weights.DEFAULT,\n",
    "                'regnet_x_8gf' : RegNet_X_8GF_Weights.DEFAULT,\n",
    "                'swin_t' : Swin_T_Weights.DEFAULT,\n",
    "                'wide_resnet50_2' : Wide_ResNet50_2_Weights.DEFAULT}\n",
    "\n",
    "    model_dict = {'convnext_tiny': convnext_tiny(weights = weight_dict['convnext_tiny']).to(device),\n",
    "                'efficientnet_v2_s' : efficientnet_v2_s(weights = weight_dict['efficientnet_v2_s']).to(device),\n",
    "                'regnet_x_8gf' : regnet_x_8gf(weights = weight_dict['regnet_x_8gf']).to(device),\n",
    "                'swin_t' : swin_t(weights = weight_dict['swin_t']).to(device),\n",
    "                'wide_resnet50_2' : wide_resnet50_2(weights = weight_dict['wide_resnet50_2']).to(device)}\n",
    "\n",
    "    # model_name = hyperparameters['model_name']\n",
    "\n",
    "    model_name = hyperparameters['model_name']\n",
    "    attribute = hyperparameters['attribute']\n",
    "\n",
    "    pt_model_dir = \"/home/simon/Documents/computerome/done_RA_models/\"\n",
    "    pt_model_name = f'{model_name}_{attribute}'\n",
    "\n",
    "    model = model_dict[model_name]\n",
    "    change_head(model_name, model, 1)\n",
    "    \n",
    "    model.load_state_dict(torch.load(f'{pt_model_dir}{pt_model_name}_SD.pth', map_location=torch.device('cpu'))) #!!!! Remove or change map_location\n",
    "    model.eval()\n",
    "\n",
    "    return(model, weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loader\n",
    "def make_loader(batch_size, weights, attribute_dict):\n",
    "\n",
    "    data_transform = transforms.Compose([weights.transforms()])\n",
    "\n",
    "    dict_dir = '/home/simon/Documents/Bodies/data/RA/dfs/' #local\n",
    "    img_dir = '/media/simon/Seagate Expansion Drive/images_spanner' #local\n",
    "    \n",
    "    image_dataset = CustomImageDataset(img_dir, attribute_dict, transform=data_transform)\n",
    "    dataloader = DataLoader(image_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    dataset_size = len(image_dataset)\n",
    "\n",
    "    return dataloader, dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make(hyperparameters):\n",
    "\n",
    "    # Make the model\n",
    "    model, weight_dict = get_model(hyperparameters)\n",
    "\n",
    "    model_name = hyperparameters['model_name']\n",
    "\n",
    "    #Choose model and wieghts\n",
    "    weights = weight_dict[model_name] # you need these later right as they hold the appropiate data transforamtions\n",
    "    model = model.to(device)\n",
    "    # wandb.watch(model)\n",
    "    \n",
    "    # is this an ok place? \n",
    "    dict_dir = '/home/simon/Documents/Bodies/data/RA/dfs/' # change to computerome location\n",
    "    with open(f'{dict_dir}ra_ens_annotated_dict.pkl', 'rb') as file:\n",
    "        attribute_dict = pickle.load(file)\n",
    "\n",
    "    # Make the data\n",
    "    dataloader, dataset_size = make_loader(batch_size=hyperparameters['batch_size'],  weights = weights, attribute_dict = attribute_dict)\n",
    "\n",
    "    return model, dataloader, dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_loader):\n",
    "    model.eval() # one more time why not.\n",
    "\n",
    "    image_list = []\n",
    "    score_list = []\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    # Run the model on some test examples\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for images, img_id in test_loader:\n",
    "            while count < 10:\n",
    "                \n",
    "                images = images.to(device)\n",
    "                outputs = model(images)\n",
    "\n",
    "                image_list.append(img_id) # might want to list or flatten the output first and then add it to the list, not append...\n",
    "                score_list.append(outputs)\n",
    "\n",
    "                count += 1\n",
    "\n",
    "    return(image_list, score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new head: Linear(in_features=768, out_features=1, bias=False)\n",
      "ConvNeXt(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2dNormActivation(\n",
      "      (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
      "      (1): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=96, out_features=384, bias=True)\n",
      "          (4): GELU(approximate=none)\n",
      "          (5): Linear(in_features=384, out_features=96, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
      "      )\n",
      "      (1): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=96, out_features=384, bias=True)\n",
      "          (4): GELU(approximate=none)\n",
      "          (5): Linear(in_features=384, out_features=96, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.0058823529411764705, mode=row)\n",
      "      )\n",
      "      (2): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=96, out_features=384, bias=True)\n",
      "          (4): GELU(approximate=none)\n",
      "          (5): Linear(in_features=384, out_features=96, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.011764705882352941, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n",
      "      (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=192, out_features=768, bias=True)\n",
      "          (4): GELU(approximate=none)\n",
      "          (5): Linear(in_features=768, out_features=192, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.017647058823529415, mode=row)\n",
      "      )\n",
      "      (1): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=192, out_features=768, bias=True)\n",
      "          (4): GELU(approximate=none)\n",
      "          (5): Linear(in_features=768, out_features=192, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.023529411764705882, mode=row)\n",
      "      )\n",
      "      (2): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=192, out_features=768, bias=True)\n",
      "          (4): GELU(approximate=none)\n",
      "          (5): Linear(in_features=768, out_features=192, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.029411764705882353, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (4): GELU(approximate=none)\n",
      "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.03529411764705883, mode=row)\n",
      "      )\n",
      "      (1): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (4): GELU(approximate=none)\n",
      "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.0411764705882353, mode=row)\n",
      "      )\n",
      "      (2): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (4): GELU(approximate=none)\n",
      "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.047058823529411764, mode=row)\n",
      "      )\n",
      "      (3): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (4): GELU(approximate=none)\n",
      "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.052941176470588235, mode=row)\n",
      "      )\n",
      "      (4): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (4): GELU(approximate=none)\n",
      "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.058823529411764705, mode=row)\n",
      "      )\n",
      "      (5): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (4): GELU(approximate=none)\n",
      "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.06470588235294118, mode=row)\n",
      "      )\n",
      "      (6): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (4): GELU(approximate=none)\n",
      "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.07058823529411766, mode=row)\n",
      "      )\n",
      "      (7): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (4): GELU(approximate=none)\n",
      "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.07647058823529412, mode=row)\n",
      "      )\n",
      "      (8): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (4): GELU(approximate=none)\n",
      "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.0823529411764706, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
      "    )\n",
      "    (7): Sequential(\n",
      "      (0): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (4): GELU(approximate=none)\n",
      "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.08823529411764706, mode=row)\n",
      "      )\n",
      "      (1): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (4): GELU(approximate=none)\n",
      "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.09411764705882353, mode=row)\n",
      "      )\n",
      "      (2): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (4): GELU(approximate=none)\n",
      "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "  (classifier): Sequential(\n",
      "    (0): LayerNorm2d((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (1): Flatten(start_dim=1, end_dim=-1)\n",
      "    (2): Linear(in_features=768, out_features=1, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# make the model, data, and optimization problem\n",
    "model, dataloader, dataset_size = make(hyperparameters)\n",
    "#print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/simon/Documents/Bodies/scripts/RA/Relative_attributes/Networks/Predicting/PredLoop.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/simon/Documents/Bodies/scripts/RA/Relative_attributes/Networks/Predicting/PredLoop.ipynb#X41sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m image_list, score_list \u001b[39m=\u001b[39m predict(model, dataloader)\n",
      "\u001b[1;32m/home/simon/Documents/Bodies/scripts/RA/Relative_attributes/Networks/Predicting/PredLoop.ipynb Cell 11\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(model, test_loader)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/simon/Documents/Bodies/scripts/RA/Relative_attributes/Networks/Predicting/PredLoop.ipynb#X41sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Run the model on some test examples\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/simon/Documents/Bodies/scripts/RA/Relative_attributes/Networks/Predicting/PredLoop.ipynb#X41sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/simon/Documents/Bodies/scripts/RA/Relative_attributes/Networks/Predicting/PredLoop.ipynb#X41sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mfor\u001b[39;00m images, img_id \u001b[39min\u001b[39;00m test_loader:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/simon/Documents/Bodies/scripts/RA/Relative_attributes/Networks/Predicting/PredLoop.ipynb#X41sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         images \u001b[39m=\u001b[39m images\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/simon/Documents/Bodies/scripts/RA/Relative_attributes/Networks/Predicting/PredLoop.ipynb#X41sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         outputs \u001b[39m=\u001b[39m model(images)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_2022/lib/python3.8/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    682\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_2022/lib/python3.8/site-packages/torch/utils/data/dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    720\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    723\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_2022/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_2022/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[1;32m/home/simon/Documents/Bodies/scripts/RA/Relative_attributes/Networks/Predicting/PredLoop.ipynb Cell 11\u001b[0m in \u001b[0;36mCustomImageDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/simon/Documents/Bodies/scripts/RA/Relative_attributes/Networks/Predicting/PredLoop.ipynb#X41sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m img_id \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimg_id[idx]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/simon/Documents/Bodies/scripts/RA/Relative_attributes/Networks/Predicting/PredLoop.ipynb#X41sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m img_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimg_dir, img_id)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/simon/Documents/Bodies/scripts/RA/Relative_attributes/Networks/Predicting/PredLoop.ipynb#X41sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m image \u001b[39m=\u001b[39m read_image(img_path)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/simon/Documents/Bodies/scripts/RA/Relative_attributes/Networks/Predicting/PredLoop.ipynb#X41sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/simon/Documents/Bodies/scripts/RA/Relative_attributes/Networks/Predicting/PredLoop.ipynb#X41sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     image \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(image)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_2022/lib/python3.8/site-packages/torchvision/io/image.py:251\u001b[0m, in \u001b[0;36mread_image\u001b[0;34m(path, mode)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mis_scripting() \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mis_tracing():\n\u001b[1;32m    250\u001b[0m     _log_api_usage_once(read_image)\n\u001b[0;32m--> 251\u001b[0m data \u001b[39m=\u001b[39m read_file(path)\n\u001b[1;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m decode_image(data, mode)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_2022/lib/python3.8/site-packages/torchvision/io/image.py:47\u001b[0m, in \u001b[0;36mread_file\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mis_scripting() \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mis_tracing():\n\u001b[1;32m     46\u001b[0m     _log_api_usage_once(read_file)\n\u001b[0;32m---> 47\u001b[0m data \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mops\u001b[39m.\u001b[39;49mimage\u001b[39m.\u001b[39;49mread_file(path)\n\u001b[1;32m     48\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_2022/lib/python3.8/site-packages/torch/_ops.py:143\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    139\u001b[0m     \u001b[39m# overloading __call__ to ensure torch.ops.foo.bar()\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     \u001b[39m# is still callable from JIT\u001b[39;00m\n\u001b[1;32m    141\u001b[0m     \u001b[39m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[1;32m    142\u001b[0m     \u001b[39m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[0;32m--> 143\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_op(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs \u001b[39mor\u001b[39;49;00m {})\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "image_list, score_list = predict(model, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the loop.\n",
    "# save it all in a dict and pkl it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # and use them to train the model\n",
    "# train(model, dataloaders['train'], criterion, optimizer, config)\n",
    "\n",
    "# # and test its final performance\n",
    "# test(model, dataloaders['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, weight_dict = get_model(hyperparameters) # working!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('torch_2022')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c861190dc1f6bbb148ba5b7a2d7833f4e7542a6e06a051c902737eff7c357b5f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
